from __future__ import annotations

"""PDF and CSV export for meeting analysis reports.

- PDF: fpdf2 (pure-Python, no system dependencies)
- CSV: ZIP file with engagement.csv, transcript.csv, participants.csv,
       coaching.csv, correlations.csv, personality.csv, signal_snapshots.csv
- Chart: matplotlib engagement timeline embedded in PDF
"""

import csv
import io
import json
import logging
import os
import tempfile
import zipfile
from typing import Optional

import aiosqlite
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from fpdf import FPDF

from .models import DB_PATH

logger = logging.getLogger(__name__)


def _safe_latin1(text: str) -> str:
    """Sanitize text for fpdf2 Helvetica (latin-1 only). Replace unsupported chars."""
    return text.encode("latin-1", errors="replace").decode("latin-1")


# ---------------------------------------------------------------------------
# Color constants
# ---------------------------------------------------------------------------
HEADING_BLUE = (30, 64, 175)
BODY_BLACK = (0, 0, 0)
META_GRAY = (100, 116, 139)
TABLE_HEADER_BG = (30, 64, 175)
TABLE_HEADER_FG = (255, 255, 255)
TABLE_ALT_ROW = (240, 245, 255)
TABLE_BORDER = (200, 210, 230)
WHITE = (255, 255, 255)


# ---------------------------------------------------------------------------
# FPDF subclass with footer
# ---------------------------------------------------------------------------

class InsightAIPDF(FPDF):
    """FPDF subclass that renders a footer on every page."""

    def footer(self):
        self.set_y(-15)
        self.set_font("Helvetica", "I", 8)
        self.set_text_color(*META_GRAY)
        self.cell(
            0, 10,
            _safe_latin1("Generated by InsightAI | Simpleem Meeting Intelligence"),
            align="C",
        )


# ---------------------------------------------------------------------------
# Engagement chart generation
# ---------------------------------------------------------------------------

async def _generate_engagement_chart(video_id: str) -> str | None:
    """Generate engagement timeline chart as PNG, return file path or None."""
    async with aiosqlite.connect(DB_PATH) as db:
        db.row_factory = aiosqlite.Row
        cursor = await db.execute(
            "SELECT timestamp, engagement FROM emotions WHERE video_id = ? ORDER BY timestamp",
            (video_id,),
        )
        rows = await cursor.fetchall()
        if not rows or len(rows) < 2:
            return None

    timestamps = [r["timestamp"] / 60 for r in rows]  # convert to minutes
    engagement = [r["engagement"] for r in rows]

    fig, ax = plt.subplots(figsize=(10, 2.5))
    ax.fill_between(timestamps, engagement, alpha=0.25, color='#1e40af')
    ax.plot(timestamps, engagement, color='#1e40af', linewidth=1.8)
    ax.set_xlabel('Time (min)', fontsize=8, color='#64748b')
    ax.set_ylabel('Engagement %', fontsize=8, color='#64748b')
    ax.set_ylim(0, 100)
    ax.set_facecolor('#f8fafc')
    fig.patch.set_facecolor('#f8fafc')
    ax.tick_params(colors='#64748b', labelsize=7)
    for spine in ['top', 'right']:
        ax.spines[spine].set_visible(False)
    ax.spines['bottom'].set_color('#e2e8f0')
    ax.spines['left'].set_color('#e2e8f0')
    plt.tight_layout()

    tmp = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
    fig.savefig(tmp.name, dpi=150, bbox_inches='tight')
    plt.close(fig)
    return tmp.name


# ---------------------------------------------------------------------------
# CSV export
# ---------------------------------------------------------------------------

async def generate_csv_export(video_id: str) -> bytes:
    """Generate a ZIP file containing CSV exports of all meeting data.

    Returns bytes of the ZIP file.
    """
    async with aiosqlite.connect(DB_PATH) as db:
        db.row_factory = aiosqlite.Row

        # Video info
        cursor = await db.execute("SELECT * FROM videos WHERE id = ?", (video_id,))
        video = await cursor.fetchone()
        if not video:
            raise ValueError(f"Video {video_id} not found")

        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
            # Participants CSV
            cursor = await db.execute(
                "SELECT * FROM participants WHERE video_id = ?", (video_id,)
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["name", "engagement_score", "sentiment_score", "speaking_pct",
                 "clarity_score", "rapport_score", "energy_score"],
            )
            zf.writestr("participants.csv", csv_str)

            # Emotions/Engagement CSV
            cursor = await db.execute(
                "SELECT * FROM emotions WHERE video_id = ? ORDER BY timestamp",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["timestamp", "participant_id", "emotion", "confidence", "engagement"],
            )
            zf.writestr("engagement.csv", csv_str)

            # Transcript CSV
            cursor = await db.execute(
                "SELECT * FROM transcript_segments WHERE video_id = ? ORDER BY start_time",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["start_time", "end_time", "speaker", "text"],
            )
            zf.writestr("transcript.csv", csv_str)

            # Flags CSV
            cursor = await db.execute(
                "SELECT * FROM flags WHERE video_id = ? ORDER BY timestamp",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["timestamp", "type", "description", "severity"],
            )
            zf.writestr("flags.csv", csv_str)

            # Voice signals CSV
            cursor = await db.execute(
                "SELECT * FROM voice_signals WHERE video_id = ? ORDER BY timestamp",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["timestamp", "tone", "pace", "energy", "dynamics"],
            )
            zf.writestr("voice_signals.csv", csv_str)

            # Word signals CSV
            cursor = await db.execute(
                "SELECT * FROM word_signals WHERE video_id = ? ORDER BY timestamp",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["timestamp", "sentiment", "sentiment_score", "keywords", "key_phrases"],
            )
            zf.writestr("word_signals.csv", csv_str)

            # Coaching CSV
            cursor = await db.execute(
                """SELECT c.recommendation, c.category, c.priority, p.name as participant_name
                   FROM coaching c JOIN participants p ON c.participant_id = p.id
                   WHERE c.video_id = ? ORDER BY p.name, c.priority""",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["participant_name", "recommendation", "category", "priority"],
            )
            zf.writestr("coaching.csv", csv_str)

            # Correlations CSV
            cursor = await db.execute(
                "SELECT * FROM correlations WHERE video_id = ?", (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["signal_pair", "pattern", "confidence", "implication"],
            )
            zf.writestr("correlations.csv", csv_str)

            # Personality CSV
            cursor = await db.execute(
                """SELECT ps.traits, ps.communication_style, ps.confidence_level,
                          p.name as participant_name
                   FROM personality_signals ps
                   JOIN participants p ON ps.participant_id = p.id
                   WHERE ps.video_id = ? ORDER BY p.name""",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["participant_name", "traits", "communication_style", "confidence_level"],
            )
            zf.writestr("personality.csv", csv_str)

            # Signal snapshots CSV
            cursor = await db.execute(
                """SELECT timestamp, participant_id, emotion, engagement,
                          posture, openness, leaning, gestures, reactions
                   FROM signal_snapshots
                   WHERE video_id = ? ORDER BY timestamp""",
                (video_id,),
            )
            rows = await cursor.fetchall()
            csv_str = _rows_to_csv(
                rows,
                ["timestamp", "participant_id", "emotion", "engagement",
                 "posture", "openness", "leaning", "gestures", "reactions"],
            )
            zf.writestr("signal_snapshots.csv", csv_str)

            # Summary
            cursor = await db.execute(
                "SELECT * FROM summaries WHERE video_id = ?", (video_id,)
            )
            row = await cursor.fetchone()
            if row:
                summary_str = f"Summary\n{row['summary']}\n\nKey Topics\n{row['key_topics']}\n\nOverall Sentiment\n{row['overall_sentiment']}"
                zf.writestr("summary.txt", summary_str)

        return zip_buffer.getvalue()


# ---------------------------------------------------------------------------
# PDF export
# ---------------------------------------------------------------------------

async def generate_pdf_report(video_id: str) -> bytes:
    """Generate a PDF report from meeting analysis data.

    Uses fpdf2 (pure-Python, no system dependencies).
    Returns bytes of the PDF file.
    """
    async with aiosqlite.connect(DB_PATH) as db:
        db.row_factory = aiosqlite.Row

        cursor = await db.execute("SELECT * FROM videos WHERE id = ?", (video_id,))
        video = await cursor.fetchone()
        if not video:
            raise ValueError(f"Video {video_id} not found")

        cursor = await db.execute(
            "SELECT * FROM participants WHERE video_id = ?", (video_id,)
        )
        participants = await cursor.fetchall()

        cursor = await db.execute(
            "SELECT * FROM summaries WHERE video_id = ?", (video_id,)
        )
        summary = await cursor.fetchone()

        cursor = await db.execute(
            "SELECT * FROM flags WHERE video_id = ? ORDER BY timestamp", (video_id,)
        )
        flags = await cursor.fetchall()

        cursor = await db.execute(
            "SELECT * FROM transcript_segments WHERE video_id = ? ORDER BY start_time",
            (video_id,),
        )
        transcript = await cursor.fetchall()

        # Coaching recommendations (joined with participant names)
        cursor = await db.execute(
            """SELECT c.*, p.name as participant_name
               FROM coaching c JOIN participants p ON c.participant_id = p.id
               WHERE c.video_id = ? ORDER BY p.name, c.priority""",
            (video_id,),
        )
        coaching = await cursor.fetchall()

        # Cross-signal correlations
        cursor = await db.execute(
            "SELECT * FROM correlations WHERE video_id = ?", (video_id,),
        )
        correlations = await cursor.fetchall()

        # Personality signals
        cursor = await db.execute(
            """SELECT ps.traits, ps.communication_style, ps.confidence_level, p.name
               FROM personality_signals ps JOIN participants p ON ps.participant_id = p.id
               WHERE ps.video_id = ?""",
            (video_id,),
        )
        personality = await cursor.fetchall()

        # Meeting notes
        cursor = await db.execute(
            "SELECT action_items, decisions, follow_ups, key_questions FROM meeting_notes WHERE video_id = ?",
            (video_id,),
        )
        meeting_notes = await cursor.fetchone()

    # Generate engagement chart (needs its own DB connection via helper)
    chart_path = await _generate_engagement_chart(video_id)

    return _build_pdf(
        video, participants, summary, flags, transcript,
        coaching, correlations, chart_path, personality, meeting_notes,
    )


# ---------------------------------------------------------------------------
# PDF helper: check if we need a new page
# ---------------------------------------------------------------------------

def _ensure_space(pdf: InsightAIPDF, needed_height: float):
    """Add a new page if the remaining space is less than needed_height."""
    if pdf.get_y() + needed_height > pdf.h - 15:
        pdf.add_page()


# ---------------------------------------------------------------------------
# PDF helper: section heading
# ---------------------------------------------------------------------------

def _section_heading(pdf: InsightAIPDF, title: str):
    """Render a blue section heading with underline."""
    _ensure_space(pdf, 18)
    pdf.set_font("Helvetica", "B", 14)
    pdf.set_text_color(*HEADING_BLUE)
    pdf.cell(0, 10, _safe_latin1(title), new_x="LMARGIN", new_y="NEXT")
    # Draw accent line under heading
    y = pdf.get_y()
    pdf.set_draw_color(*HEADING_BLUE)
    pdf.set_line_width(0.5)
    pdf.line(pdf.l_margin, y, pdf.l_margin + 60, y)
    pdf.set_line_width(0.2)
    pdf.ln(3)


# ---------------------------------------------------------------------------
# PDF helper: draw a table
# ---------------------------------------------------------------------------

def _draw_table(pdf: InsightAIPDF, headers: list, col_widths: list, rows: list,
                multi_cell_cols: set | None = None):
    """Draw a bordered table with header row and alternating row colors.

    Args:
        pdf: The PDF instance.
        headers: List of header strings.
        col_widths: List of column widths (mm).
        rows: List of row tuples/lists, each with len == len(headers).
        multi_cell_cols: Set of column indices that should use multi_cell
                         (for wrapping long text). If None, all use cell.
    """
    if multi_cell_cols is None:
        multi_cell_cols = set()

    row_height = 6
    header_height = 8

    # -- Header row --
    _ensure_space(pdf, header_height + row_height * 2)
    pdf.set_font("Helvetica", "B", 9)
    pdf.set_fill_color(*TABLE_HEADER_BG)
    pdf.set_text_color(*TABLE_HEADER_FG)
    pdf.set_draw_color(*TABLE_BORDER)
    x_start = pdf.get_x()
    for i, h in enumerate(headers):
        pdf.cell(col_widths[i], header_height, _safe_latin1(h),
                 border=1, fill=True, align="C")
    pdf.ln()

    # -- Data rows --
    pdf.set_font("Helvetica", "", 9)
    pdf.set_text_color(*BODY_BLACK)

    for row_idx, row_data in enumerate(rows):
        # Determine if any multi_cell column exists to calculate row height
        if multi_cell_cols:
            # Calculate the tallest cell height for this row
            max_lines = 1
            for ci in multi_cell_cols:
                if ci < len(row_data):
                    text = str(row_data[ci]) if row_data[ci] else ""
                    # Approximate number of lines: chars / chars_per_line
                    chars_per_line = max(1, int(col_widths[ci] / 1.8))
                    n_lines = max(1, -(-len(text) // chars_per_line))  # ceiling div
                    max_lines = max(max_lines, n_lines)
            computed_row_h = max(row_height, max_lines * row_height)
        else:
            computed_row_h = row_height

        _ensure_space(pdf, computed_row_h + 2)

        # Alternating row fill
        if row_idx % 2 == 1:
            pdf.set_fill_color(*TABLE_ALT_ROW)
        else:
            pdf.set_fill_color(*WHITE)

        x_row_start = pdf.get_x()
        y_row_start = pdf.get_y()

        # Draw each cell
        tallest = 0
        for ci in range(len(headers)):
            cell_text = _safe_latin1(str(row_data[ci]) if ci < len(row_data) and row_data[ci] is not None else "")
            pdf.set_xy(x_row_start + sum(col_widths[:ci]), y_row_start)

            if ci in multi_cell_cols:
                # Use multi_cell for wrapping
                pdf.multi_cell(col_widths[ci], row_height, cell_text,
                               border=1, fill=True, new_x="RIGHT", new_y="TOP")
                cell_bottom = pdf.get_y() + (pdf.get_y() - y_row_start)
                # Track how far down we went
                actual_h = pdf.get_y() - y_row_start
                if actual_h < row_height:
                    actual_h = row_height
                tallest = max(tallest, actual_h)
            else:
                pdf.cell(col_widths[ci], computed_row_h, cell_text,
                         border=1, fill=True)
                tallest = max(tallest, computed_row_h)

        pdf.set_xy(x_row_start, y_row_start + tallest)

    pdf.ln(2)


def _estimate_multicell_height(pdf: InsightAIPDF, text: str, col_width: float,
                                line_h: float) -> float:
    """Estimate the height a multi_cell would occupy for the given text and width.

    Uses word-based line wrapping estimation with fpdf2 string width measurements.
    Falls back to character-based estimation if needed.
    """
    if not text:
        return line_h

    usable_w = col_width - 2  # account for cell padding
    if usable_w <= 0:
        return line_h

    # Try using fpdf2's dry_run if available (fpdf2 >= 2.7.5)
    try:
        result = pdf.multi_cell(usable_w, line_h, text, dry_run=True, output="HEIGHT")
        if result and result > 0:
            return max(line_h, result)
    except TypeError:
        pass  # dry_run not supported in this fpdf2 version

    # Word-based estimation fallback
    avg_char_w = pdf.get_string_width("n")
    if avg_char_w <= 0:
        avg_char_w = 2.0

    chars_per_line = max(1, int(usable_w / avg_char_w))
    words = text.split()
    if not words:
        return line_h

    current_line_len = 0
    n_lines = 1
    for word in words:
        wlen = len(word)
        if current_line_len > 0 and current_line_len + 1 + wlen > chars_per_line:
            n_lines += 1
            current_line_len = wlen
        else:
            current_line_len += (1 if current_line_len > 0 else 0) + wlen

    return max(line_h, n_lines * line_h)


def _draw_table_multicell(pdf: InsightAIPDF, headers: list, col_widths: list,
                           rows: list, wrap_cols: set | None = None):
    """Draw a table where specific columns use multi_cell for text wrapping.

    Properly handles row height alignment across all columns when some
    columns wrap text. Uses a three-step approach per row:
      1. Estimate row height from wrap columns
      2. Draw filled/bordered rectangles for all cells at that height
      3. Write text into each cell

    Args:
        pdf: The PDF instance.
        headers: List of header strings.
        col_widths: List of column widths (mm).
        rows: List of row tuples/lists.
        wrap_cols: Set of column indices that wrap text. Default: empty.
    """
    if wrap_cols is None:
        wrap_cols = set()

    line_h = 5
    header_h = 8

    # -- Header --
    _ensure_space(pdf, header_h + line_h * 2)
    pdf.set_font("Helvetica", "B", 9)
    pdf.set_fill_color(*TABLE_HEADER_BG)
    pdf.set_text_color(*TABLE_HEADER_FG)
    pdf.set_draw_color(*TABLE_BORDER)
    for i, h in enumerate(headers):
        pdf.cell(col_widths[i], header_h, _safe_latin1(h),
                 border=1, fill=True, align="C")
    pdf.ln()

    # -- Data rows --
    pdf.set_font("Helvetica", "", 9)
    pdf.set_text_color(*BODY_BLACK)

    for row_idx, row_data in enumerate(rows):
        # Prepare cell texts
        cell_texts = []
        for ci in range(len(headers)):
            val = row_data[ci] if ci < len(row_data) and row_data[ci] is not None else ""
            cell_texts.append(_safe_latin1(str(val)))

        # Step 1: Estimate row height from wrap columns
        row_h = line_h
        for ci in wrap_cols:
            if ci < len(cell_texts) and cell_texts[ci]:
                est = _estimate_multicell_height(pdf, cell_texts[ci],
                                                  col_widths[ci], line_h)
                row_h = max(row_h, est)

        # Cap at reasonable max to prevent absurdly tall rows
        row_h = min(row_h, 120)

        # Ensure enough page space; add a page if needed
        _ensure_space(pdf, row_h + 2)

        # Set alternating row fill color
        if row_idx % 2 == 1:
            pdf.set_fill_color(*TABLE_ALT_ROW)
        else:
            pdf.set_fill_color(*WHITE)

        x_start = pdf.l_margin
        y_start = pdf.get_y()

        # Step 2: Draw filled background rectangles and borders for each cell
        pdf.set_draw_color(*TABLE_BORDER)
        for ci in range(len(headers)):
            cx = x_start + sum(col_widths[:ci])
            pdf.rect(cx, y_start, col_widths[ci], row_h, style="DF")

        # Step 3: Write text into each cell
        pdf.set_text_color(*BODY_BLACK)
        for ci in range(len(headers)):
            cx = x_start + sum(col_widths[:ci])
            pdf.set_xy(cx + 1, y_start + 1)  # small padding inside cell

            if ci in wrap_cols:
                pdf.multi_cell(col_widths[ci] - 2, line_h, cell_texts[ci],
                               border=0, fill=False, new_x="RIGHT", new_y="TOP")
            else:
                pdf.cell(col_widths[ci] - 2, line_h, cell_texts[ci],
                         border=0, fill=False)

        # Move cursor below this row
        pdf.set_xy(x_start, y_start + row_h)

    pdf.ln(2)


# ---------------------------------------------------------------------------
# Main PDF builder
# ---------------------------------------------------------------------------

def _build_pdf(
    video, participants, summary, flags, transcript,
    coaching, correlations, chart_path, personality, meeting_notes,
) -> bytes:
    """Build a styled landscape PDF report using fpdf2."""
    pdf = InsightAIPDF(orientation='L')
    pdf.set_auto_page_break(auto=True, margin=15)

    # Usable width in landscape A4: 297 - 10 - 10 = 277 mm
    page_w = 277

    # =====================================================================
    # TITLE PAGE
    # =====================================================================
    pdf.add_page()

    # Large title
    pdf.ln(30)
    pdf.set_font("Helvetica", "B", 32)
    pdf.set_text_color(*HEADING_BLUE)
    pdf.cell(0, 16, _safe_latin1("InsightAI Meeting Analysis Report"),
             align="C", new_x="LMARGIN", new_y="NEXT")
    pdf.ln(4)

    # Decorative line
    pdf.set_draw_color(*HEADING_BLUE)
    pdf.set_line_width(1.0)
    center_x = pdf.l_margin + page_w / 2
    pdf.line(center_x - 60, pdf.get_y(), center_x + 60, pdf.get_y())
    pdf.set_line_width(0.2)
    pdf.ln(12)

    # Meeting metadata
    duration_min = round((video["duration"] or 0) / 60, 1)
    overall = round(video["overall_score"]) if video["overall_score"] else 0
    created = video["created_at"] or ""

    meta_items = [
        ("Meeting", str(video["name"] or "Untitled")),
        ("Duration", f"{duration_min} minutes"),
        ("Participants", str(len(participants))),
        ("Date", created[:10] if len(created) >= 10 else created),
        ("Overall Score", f"{overall}%"),
    ]

    pdf.set_font("Helvetica", "", 12)
    for label, value in meta_items:
        pdf.set_text_color(*META_GRAY)
        label_w = pdf.get_string_width(label + ":  ") + 2
        # Center the block
        block_w = label_w + pdf.get_string_width(value) + 4
        pdf.set_x(pdf.l_margin + (page_w - block_w) / 2)
        pdf.set_font("Helvetica", "", 12)
        pdf.set_text_color(*META_GRAY)
        pdf.cell(label_w, 8, _safe_latin1(f"{label}: "))
        pdf.set_font("Helvetica", "B", 12)
        pdf.set_text_color(*BODY_BLACK)
        pdf.cell(0, 8, _safe_latin1(value), new_x="LMARGIN", new_y="NEXT")

    # =====================================================================
    # SUMMARY SECTION
    # =====================================================================
    pdf.add_page()

    _section_heading(pdf, "Executive Summary")
    summary_text = summary["summary"] if summary and summary["summary"] else "No summary available."
    pdf.set_font("Helvetica", "", 10)
    pdf.set_text_color(*BODY_BLACK)
    pdf.multi_cell(page_w, 5, _safe_latin1(summary_text),
                   new_x="LMARGIN", new_y="NEXT")
    pdf.ln(3)

    key_topics = []
    if summary and summary["key_topics"]:
        try:
            key_topics = json.loads(summary["key_topics"])
        except (json.JSONDecodeError, TypeError):
            pass
    if key_topics:
        pdf.set_font("Helvetica", "B", 10)
        pdf.set_text_color(*HEADING_BLUE)
        pdf.cell(28, 6, "Key Topics: ")
        pdf.set_font("Helvetica", "", 10)
        pdf.set_text_color(*BODY_BLACK)
        pdf.cell(0, 6, _safe_latin1(", ".join(str(t) for t in key_topics)),
                 new_x="LMARGIN", new_y="NEXT")
    pdf.ln(6)

    # =====================================================================
    # ENGAGEMENT TIMELINE CHART
    # =====================================================================
    if chart_path:
        _section_heading(pdf, "Engagement Timeline")
        _ensure_space(pdf, 55)
        pdf.image(chart_path, x=pdf.l_margin, w=page_w)
        pdf.ln(6)
        try:
            os.remove(chart_path)
        except OSError:
            pass

    # =====================================================================
    # PARTICIPANTS TABLE
    # =====================================================================
    _section_heading(pdf, "Participants")
    p_headers = ["Name", "Engagement", "Sentiment", "Clarity", "Rapport", "Energy", "Speaking %"]
    # Distribute widths across landscape page
    p_widths = [70, 35, 35, 35, 35, 35, 32]

    p_rows = []
    for p in participants:
        p_rows.append([
            str(p["name"] or ""),
            f'{round(p["engagement_score"])}%',
            f'{round(p["sentiment_score"])}%' if p["sentiment_score"] else "N/A",
            f'{round(p["clarity_score"])}%',
            f'{round(p["rapport_score"])}%',
            f'{round(p["energy_score"])}%',
            f'{round(p["speaking_pct"])}%',
        ])
    _draw_table(pdf, p_headers, p_widths, p_rows)
    pdf.ln(4)

    # =====================================================================
    # PERSONALITY TRAITS TABLE
    # =====================================================================
    if personality:
        _section_heading(pdf, "Personality Traits")
        pers_headers = ["Participant", "Traits", "Communication Style", "Confidence"]
        pers_widths = [50, 100, 80, 47]

        pers_rows = []
        for ps in personality:
            traits_raw = ps["traits"] or "[]"
            try:
                traits_list = json.loads(traits_raw) if isinstance(traits_raw, str) else traits_raw
                if isinstance(traits_list, list):
                    traits_str = ", ".join(str(t) for t in traits_list)
                else:
                    traits_str = str(traits_list)
            except (json.JSONDecodeError, TypeError):
                traits_str = str(traits_raw)

            pers_rows.append([
                str(ps["name"] or ""),
                traits_str,
                str(ps["communication_style"] or ""),
                str(ps["confidence_level"] or ""),
            ])
        _draw_table_multicell(pdf, pers_headers, pers_widths, pers_rows, wrap_cols={1, 2})
        pdf.ln(4)

    # =====================================================================
    # COACHING RECOMMENDATIONS TABLE
    # =====================================================================
    if coaching:
        _section_heading(pdf, "Coaching Recommendations")
        c_headers = ["Participant", "Category", "Recommendation"]
        c_widths = [50, 40, 187]

        c_rows = []
        for item in coaching:
            c_rows.append([
                str(item["participant_name"] or ""),
                str(item["category"] or ""),
                str(item["recommendation"] or ""),  # Full text, no truncation
            ])
        _draw_table_multicell(pdf, c_headers, c_widths, c_rows, wrap_cols={2})
        pdf.ln(4)

    # =====================================================================
    # CROSS-SIGNAL CORRELATIONS
    # =====================================================================
    if correlations:
        _section_heading(pdf, "Cross-Signal Correlations")
        cor_headers = ["Signal Pair", "Pattern", "Confidence", "Implication"]
        cor_widths = [55, 90, 25, 107]

        cor_rows = []
        for corr in correlations:
            signal_pair = corr["signal_pair"]
            try:
                sp = json.loads(signal_pair) if isinstance(signal_pair, str) else signal_pair
                if isinstance(sp, list):
                    label = " <-> ".join(str(s) for s in sp)
                else:
                    label = str(sp)
            except (json.JSONDecodeError, TypeError):
                label = str(signal_pair)

            conf = corr["confidence"]
            conf_str = f'{round(conf * 100)}%' if conf is not None else "N/A"

            cor_rows.append([
                label,
                str(corr["pattern"] or ""),
                conf_str,
                str(corr["implication"] or ""),
            ])
        _draw_table_multicell(pdf, cor_headers, cor_widths, cor_rows, wrap_cols={1, 3})
        pdf.ln(4)

    # =====================================================================
    # CRITICAL MOMENTS / FLAGS TABLE
    # =====================================================================
    if flags:
        _section_heading(pdf, "Critical Moments")
        f_headers = ["Time", "Type", "Severity", "Description"]
        f_widths = [25, 40, 25, 187]

        f_rows = []
        for f in flags:
            f_rows.append([
                _format_time(f["timestamp"]),
                str(f["type"] or ""),
                str(f["severity"] or ""),
                str(f["description"] or ""),  # Full text, no truncation
            ])
        _draw_table_multicell(pdf, f_headers, f_widths, f_rows, wrap_cols={3})
        pdf.ln(4)

    # =====================================================================
    # MEETING NOTES (action items, decisions, follow-ups, key questions)
    # =====================================================================
    if meeting_notes:
        has_content = False

        # Parse each notes field
        sections_data = []
        for field_name, display_name in [
            ("action_items", "Action Items"),
            ("decisions", "Decisions"),
            ("follow_ups", "Follow-Ups"),
            ("key_questions", "Key Questions"),
        ]:
            raw = meeting_notes[field_name] if meeting_notes[field_name] else "[]"
            try:
                items = json.loads(raw) if isinstance(raw, str) else raw
            except (json.JSONDecodeError, TypeError):
                items = []
            if items and isinstance(items, list) and len(items) > 0:
                sections_data.append((display_name, items))
                has_content = True

        if has_content:
            _section_heading(pdf, "Meeting Notes")

            for sec_name, items in sections_data:
                _ensure_space(pdf, 16)
                pdf.set_font("Helvetica", "B", 11)
                pdf.set_text_color(*HEADING_BLUE)
                pdf.cell(0, 7, _safe_latin1(sec_name), new_x="LMARGIN", new_y="NEXT")
                pdf.ln(1)

                note_headers = ["#", "Item"]
                note_widths = [15, 262]
                note_rows = []
                for idx, item in enumerate(items, 1):
                    note_rows.append([str(idx), _safe_latin1(str(item))])
                _draw_table_multicell(pdf, note_headers, note_widths, note_rows, wrap_cols={1})
                pdf.ln(3)

    # =====================================================================
    # TRANSCRIPT TABLE (ALL segments)
    # =====================================================================
    if transcript:
        _section_heading(pdf, "Transcript")
        t_headers = ["Time", "Speaker", "Text"]
        t_widths = [25, 45, 207]

        t_rows = []
        for seg in transcript:
            ts = _format_time(seg["start_time"])
            speaker = str(seg["speaker"] or "")
            text = str(seg["text"] or "")
            t_rows.append([ts, speaker, text])

        _draw_table_multicell(pdf, t_headers, t_widths, t_rows, wrap_cols={2})
        pdf.ln(4)

    return bytes(pdf.output())


def _rows_to_csv(rows, columns: list) -> str:
    """Convert aiosqlite rows to CSV string."""
    output = io.StringIO()
    writer = csv.writer(output)
    writer.writerow(columns)
    for row in rows:
        writer.writerow([row[col] for col in columns])
    return output.getvalue()


def _format_time(seconds: float) -> str:
    """Format seconds as M:SS."""
    m = int(seconds // 60)
    s = int(seconds % 60)
    return f"{m}:{s:02d}"
